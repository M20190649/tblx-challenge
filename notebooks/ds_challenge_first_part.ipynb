{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tb.lx Data Science Challenge - Part I\n",
    "----\n",
    "----\n",
    "## Introduction\n",
    "\n",
    "Dear applicant,\n",
    "\n",
    "Congratulations on passing the first screening! We’re excited to get to know you better and get a better feeling of your competences. In this round, we will test you on your problem-solving skills and data science experience by giving you a case to solve.\n",
    "\n",
    "After handing us over your solution, we will review it and let you know our feedback. In the case you have passed, you will be called to an on-site interview. During the interview, you’ll get the opportunity to explain your solution and the steps that you took to get there. We've prepared this notebook for you, to help you walk us through your ideas and decisions.\n",
    "\n",
    "If you're not able to fully solve the case, please elaborate as precisely as you can:\n",
    "\n",
    "- Which next steps you'd be taking;\n",
    "- Which problems you'd be foreseeing there and how you'd solve those.\n",
    "\n",
    "In case you have any questions, feel free to contact ana.cunha@daimler.com or sara.gorjao@daimler.com for any more info. \n",
    "\n",
    "Best of luck!\n",
    "\n",
    "## Context\n",
    "\n",
    "Working with GPS data is part of tb.lx day to day life. We need to extract and analyze patterns from fleets in order to enable intelligence over it. Just by knowing the history of the position of vehicles (latitude, longitude, and timestamp) it is possible to answer the questions we ask below. Take into consideration the following concepts:\n",
    "\n",
    "**Frequently stopping location** - Delimited location where vehicles stop regularly with a specific purpose. In the trucks world it can be warehouses, fuel stations, rest locations, etc;\n",
    "\n",
    "**Trip** - This is what results of a vehicle that moved from a '*frequently stopping location A*' to a '*frequently stopping location B*'. To make it short let's say trip(A,B);\n",
    "\n",
    "**Trajectory** - Is the actual path of the vehicle that he took to make the *trip*(A,B);\n",
    "\n",
    "<img src=\"../images/concepts.png\" style=\"width: 700px;\"/>\n",
    "\n",
    "\n",
    "## Data:\n",
    "\n",
    "In this challenge, we ask you to perform simple analyses on a vehicle telematics dataset. The dataset to use in order to answer the questions can be found associated with the paper: [Vehicle Energy Dataset (VED), A Large-scale Dataset for Vehicle Energy Consumption Research](https://arxiv.org/abs/1905.02081).\n",
    "\n",
    "#### Important: You cannot use the `Trip` column for your calculations.\n",
    "\n",
    "## Tasks:\n",
    "\n",
    "1. How would you find the *frequently stopping locations* from the data?\n",
    "2. What is the most popular *frequently stopping location*? How many vehicles start or end their *trips* there? Please identify the *frequently stopping location* using its bounding box coordinates.\n",
    "3. What is the most frequent *trip*? How many statistically different *trajectories* make up this trip?\n",
    "4. What are the *trips* with the highest and lowest average speed?\n",
    "5. Discuss the anonymization process used by the dataset authors. Are there any obvious flaws? Can you devise a way to counter it?\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "- Solution implemented in Python3.6+;\n",
    "- Provide requirements.txt to test the solution in the same environment;\n",
    "- Write well structured, documented, maintainable code;\n",
    "- Write sanity checks to test the different steps of the pipeline;\n",
    "\n",
    "## Downloading the data\n",
    "\n",
    "First we need to download the data for this analysis. We'll start by creating a folder in which to download the data and then download the data into this folder\n",
    "\n",
    "**Note:** The data folders are zipped using 7zip, so in order to unzip them 7zip must be installed in the machine to use the `7z` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'VED_data/': No such file or directory\n",
      "--2020-03-27 18:12:35--  https://raw.githubusercontent.com/gsoh/VED/master/Data/VED_DynamicData_Part1.7z\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.132.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.132.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 82723769 (79M) [application/octet-stream]\n",
      "Saving to: ‘VED_DynamicData_Part1.7z’\n",
      "\n",
      "VED_DynamicData_Par 100%[===================>]  78,89M  4,35MB/s    in 20s     \n",
      "\n",
      "2020-03-27 18:12:55 (3,97 MB/s) - ‘VED_DynamicData_Part1.7z’ saved [82723769/82723769]\n",
      "\n",
      "--2020-03-27 18:12:55--  https://raw.githubusercontent.com/gsoh/VED/master/Data/VED_DynamicData_Part2.7z\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.132.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.132.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 93662910 (89M) [application/octet-stream]\n",
      "Saving to: ‘VED_DynamicData_Part2.7z’\n",
      "\n",
      "VED_DynamicData_Par 100%[===================>]  89,32M  2,81MB/s    in 22s     \n",
      "\n",
      "2020-03-27 18:13:18 (4,00 MB/s) - ‘VED_DynamicData_Part2.7z’ saved [93662910/93662910]\n",
      "\n",
      "--2020-03-27 18:13:18--  https://raw.githubusercontent.com/gsoh/VED/master/Data/VED_Static_Data_ICE&HEV.xlsx\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.132.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.132.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 21155 (21K) [application/octet-stream]\n",
      "Saving to: ‘VED_data/VED_Static_Data_ICE&HEV.xlsx’\n",
      "\n",
      "VED_Static_Data_ICE 100%[===================>]  20,66K  --.-KB/s    in 0,03s   \n",
      "\n",
      "2020-03-27 18:13:18 (755 KB/s) - ‘VED_data/VED_Static_Data_ICE&HEV.xlsx’ saved [21155/21155]\n",
      "\n",
      "--2020-03-27 18:13:18--  https://raw.githubusercontent.com/gsoh/VED/master/Data/VED_Static_Data_PHEV&EV.xlsx\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.132.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.132.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9763 (9,5K) [application/octet-stream]\n",
      "Saving to: ‘VED_data/VED_Static_Data_PHEV&EV.xlsx’\n",
      "\n",
      "VED_Static_Data_PHE 100%[===================>]   9,53K  --.-KB/s    in 0,001s  \n",
      "\n",
      "2020-03-27 18:13:18 (7,24 MB/s) - ‘VED_data/VED_Static_Data_PHEV&EV.xlsx’ saved [9763/9763]\n",
      "\n",
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=pt_PT.UTF-8,Utf16=on,HugeFiles=on,64 bits,8 CPUs Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz (806EA),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Sca        1 file, 82723769 bytes (79 MiB)\n",
      "\n",
      "Extracting archive: VED_DynamicData_Part1.7z\n",
      "--\n",
      "Path = VED_DynamicData_Part1.7z\n",
      "Type = 7z\n",
      "Physical Size = 82723769\n",
      "Headers Size = 546\n",
      "Method = LZMA2:25\n",
      "Solid = +\n",
      "Blocks = 1\n",
      "\n",
      "      2% - VED_171101_week.c                          5% 1 - VED_171108_week.c                            8% 1 - VED_171108_week.c                           10% 2 - VED_171115_week.c                           13% 2 - VED_171115_week.c                           16% 3 - VED_171122_week.c                           19% 3 - VED_171122_week.c                           22% 4 - VED_171129_week.c                           25% 4 - VED_171129_week.c                           27% 5 - VED_171206_week.c                           30% 5 - VED_171206_week.c                           32% 6 - VED_171213_week.c                           35% 6 - VED_171213_week.c                           38% 7 - VED_171220_week.c                           41% 7 - VED_171220_week.c                           44% 8 - VED_171227_week.c                           46% 9 - VED_180103_week.c                           49% 9 - VED_180103_week.c                           51% 10 - VED_180110_week.cs                             54% 10 - VED_180110_week.cs                             56% 11 - VED_180117_week.cs                             59% 11 - VED_180117_week.cs                             61% 12 - VED_180124_week.cs                             64% 12 - VED_180124_week.cs                             67% 13 - VED_180131_week.cs                             70% 14 - VED_180207_week.cs                             73% 14 - VED_180207_week.cs                             76% 15 - VED_180214_week.cs                             79% 16 - VED_180221_week.cs                             82% 17 - VED_180228_week.cs                             85% 18 - VED_180307_week.cs                             88% 18 - VED_180307_week.cs                             91% 19 - VED_180314_week.cs                             93% 20 - VED_180321_week.cs                             94% 20 - VED_180321_week.cs                             97% 21 - VED_180328_week.cs                            100% 2      Everything is Ok\n",
      "\n",
      "Files: 22\n",
      "Size:       1463400664\n",
      "Compressed: 82723769\n",
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=pt_PT.UTF-8,Utf16=on,HugeFiles=on,64 bits,8 CPUs Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz (806EA),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Sca        1 file, 93662910 bytes (90 MiB)\n",
      "\n",
      "Extracting archive: VED_DynamicData_Part2.7z\n",
      "--\n",
      "Path = VED_DynamicData_Part2.7z\n",
      "Type = 7z\n",
      "Physical Size = 93662910\n",
      "Headers Size = 706\n",
      "Method = LZMA2:25\n",
      "Solid = +\n",
      "Blocks = 1\n",
      "\n",
      "      2% - VED_180404_week.c                          4% 1 - VED_180411_week.c                            7% 1 - VED_180411_week.c                            9% 2 - VED_180418_week.c                           12% 3 - VED_180425_week.c                           14% 3 - VED_180425_week.c                           17% 4 - VED_180502_week.c                           19% 5 - VED_180509_week.c                           21% 6 - VED_180516_week.c                           24% 6 - VED_180516_week.c                           25% 6 - VED_180516_week.c                           28% 7 - VED_180523_week.c                           30% 8 - VED_180530_week.c                           33% 9 - VED_180606_week.c                           35% 9 - VED_180606_week.c                           38% 10 - VED_180613_week.cs                             41% 11 - VED_180620_week.cs                             43% 12 - VED_180627_week.cs                             46% 12 - VED_180627_week.cs                             48% 13 - VED_180704_week.cs                             51% 14 - VED_180711_week.cs                             53% 15 - VED_180718_week.cs                             55% 16 - VED_180725_week.cs                             57% 16 - VED_180725_week.cs                             60% 17 - VED_180801_week.cs                             62% 18 - VED_180808_week.cs                             65% 19 - VED_180815_week.cs                             67% 20 - VED_180822_week.cs                             70% 21 - VED_180829_week.cs                             72% 22 - VED_180905_week.cs                             75% 23 - VED_180912_week.cs                             77% 24 - VED_180919_week.cs                             80% 24 - VED_180919_week.cs                             82% 25 - VED_180926_week.cs                             84% 26 - VED_181003_week.cs                             87% 27 - VED_181010_week.cs                             88% 27 - VED_181010_week.cs                             91% 28 - VED_181017_week.cs                             94% 29 - VED_181024_week.cs                             96% 30 - VED_181031_week.cs                             98% 31 - VED_181107_week.cs                            Everything is Ok\n",
      "\n",
      "Files: 32\n",
      "Size:       1740155065\n",
      "Compressed: 93662910\n"
     ]
    }
   ],
   "source": [
    "# Create a folder in which to place the data (Remove it if already exists)\n",
    "!rm -r VED_data/\n",
    "\n",
    "!mkdir VED_data\n",
    "\n",
    "# Download the data\n",
    "!wget https://raw.githubusercontent.com/gsoh/VED/master/Data/VED_DynamicData_Part1.7z\n",
    "!wget https://raw.githubusercontent.com/gsoh/VED/master/Data/VED_DynamicData_Part2.7z\n",
    "!wget -P VED_data https://raw.githubusercontent.com/gsoh/VED/master/Data/VED_Static_Data_ICE\\&HEV.xlsx\n",
    "!wget -P VED_data https://raw.githubusercontent.com/gsoh/VED/master/Data/VED_Static_Data_PHEV\\&EV.xlsx\n",
    "\n",
    "# Unzip the data into the folder created\n",
    "# NOTE: 7z needs to be installed in the machine\n",
    "!7z x VED_DynamicData_Part1.7z -oVED_data\n",
    "!7z x VED_DynamicData_Part2.7z -oVED_data\n",
    "\n",
    "# Delete the zip file\n",
    "!rm *.7z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Defining spark session and context\n",
    "spark = SparkSession.builder \\\n",
    "           .master('local[*]') \\\n",
    "           .appName('tblx') \\\n",
    "           .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Define the correct schema for the columns in order to optimize memory managment\n",
    "schema = StructType([\n",
    "    StructField(\"DayNum\", FloatType(), True),\n",
    "    StructField(\"VehId\", IntegerType(), True),\n",
    "    StructField(\"Trip\", StringType(), True),\n",
    "    StructField(\"Timestamp(ms)\", IntegerType(), True),\n",
    "    StructField(\"Latitude[deg]\", FloatType(), True),\n",
    "    StructField(\"Longitude[deg]\", FloatType(), True),\n",
    "    StructField(\"Vehicle Speed[km/h]\", FloatType(), False),\n",
    "    StructField(\"MAF[g/sec]\", FloatType(), True),\n",
    "    StructField(\"Absolute Load[%]\", FloatType(), True),\n",
    "    StructField(\"OAT[DegC]\", StringType(), True),\n",
    "    StructField(\"Fuel Rate[L/hr]\", StringType(), True),\n",
    "    StructField(\"Air Conditioning Power[kW]\", StringType(), True),\n",
    "    StructField(\"Air Conditioning Power[Watts]\", StringType(), True),\n",
    "    StructField(\"Heater Power[Watts]\", StringType(), True),\n",
    "    StructField(\"HV Battery Current[A]\", StringType(), True),\n",
    "    StructField(\"HV Battery SOC[%]\", StringType(), True),\n",
    "    StructField(\"HV Battery Voltage[V]\", StringType(), True),\n",
    "    StructField(\"Short Term Fuel Trim Bank 1[%]\", StringType(), True),\n",
    "    StructField(\"Short Term Fuel Trim Bank 2[%]\", StringType(), True),\n",
    "    StructField(\"Long Term Fuel Trim Bank 1[%]\", StringType(), True),\n",
    "    StructField(\"Long Term Fuel Trim Bank 2[%]\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Read all dynamic csvs into one spark dataframe\n",
    "df = spark.read.option('header', 'true').csv('./VED_data/*.csv', schema=schema)\n",
    "\n",
    "# Keeping only the needed columns\n",
    "df = df.select([\"DayNum\", \"VehId\", \"Timestamp(ms)\", \"Latitude[deg]\", \"Longitude[deg]\", \"Vehicle Speed[km/h]\"])\n",
    "\n",
    "# Replace the string \"NaN\" with null values\n",
    "df = df.replace(\"NaN\", None)\n",
    "\n",
    "# Drop rows where all values are null (sanity check)\n",
    "df = df.na.drop(how=\"all\")\n",
    "\n",
    "# Get a sample of the dataframe (using just the first two weeks here)\n",
    "first_two_weeks = df.na.drop() \\\n",
    "    .filter((df.DayNum >= 1) & (df.DayNum < 15)) \\\n",
    "    .orderBy([\"VehId\", \"DayNum\", \"Timestamp(ms)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data the pair (DayNum, VehId) seems to define a trip\n",
    "\n",
    "## 1- Defining stopping location\n",
    "\n",
    "A stopping location could viewed as be a pair of (lat, long) where a trip begins (i.e. timestamp 0) or ends (i.e. maximum timestamp for that trip). This is identical to grouping by the pair of DayNum, VehId (that identifies a trip) and taking the first and last latitude and longitude of each group since rows are also sorted by their timestamp (as specified in the cell above)\n",
    "\n",
    "However we see the anonymization process in action where the a trip starts and ends with a speed > 0, indicating that the trajectories prior to $t_{min}$ and $t_{max}$ are supressed as stated in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = first_two_weeks.groupBy([\"DayNum\", \"VehId\"])\n",
    "\n",
    "# Expression to obtain the median function of the vehicle speed\n",
    "median_function = expr('percentile_approx(`Vehicle Speed[km/h]`, 0.5)')\n",
    "\n",
    "# Get the first and last lat, long and the avg/median speed for each pair of (DayNum, VehId)\n",
    "start_locations = grouped.agg(\n",
    "    first(\"Latitude[deg]\").alias(\"Latitude\"),\n",
    "    first(\"Longitude[deg]\").alias(\"Longitude\"),\n",
    "    mean(\"Vehicle Speed[km/h]\").alias(\"Average_speed\"),\n",
    "    median_function.alias(\"Median_Speed\")\n",
    ")\n",
    "\n",
    "end_locations = grouped.agg(\n",
    "    last(\"Latitude[deg]\").alias(\"Latitude\"),\n",
    "    last(\"Longitude[deg]\").alias(\"Longitude\"),\n",
    "    mean(\"Vehicle Speed[km/h]\").alias(\"Average_speed\"),\n",
    "    median_function.alias(\"Median_Speed\")\n",
    ")\n",
    "\n",
    "# Join the two dataframes together so we have a list of stopping locations (either start or end) and the \n",
    "# avg/median speed for every trip\n",
    "# .distinct() to remove already existing stopping locations\n",
    "stopping_locations = start_locations.unionAll(end_locations).distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- What are the most popular stopping locations? How many vehicles start or end their trips there?\n",
    "\n",
    "First define the bounding box coordinates by adding and subtracting 0.0025º to lat and long and rounding the result to 3 decimal places. Rounding the result will allow for points in close locations to have the same bounding box coordinates.\n",
    "\n",
    "Here the popularity of a location will be measured by the number of distinct vehicles that start or end their trip their. It is important to consider the distinct number of vehicles that start or end their trips in this location rather than just the total number of trips, in order to make sure we are not influenced by a large number of trips that only a small number of users make (for example: only a small X percent of the users going to the supermarket everyday)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------+---------+-------------------+---------+\n",
      "|top_box|bottom_box|left_box|right_box|num_unique_vehicles|num_stops|\n",
      "+-------+----------+--------+---------+-------------------+---------+\n",
      "| 42.277|    42.272| -83.672|  -83.677|                 44|      121|\n",
      "| 42.255|     42.25| -83.672|  -83.677|                 36|       54|\n",
      "| 42.233|    42.228| -83.678|  -83.683|                 33|       67|\n",
      "+-------+----------+--------+---------+-------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the bounding box coordinates for each row\n",
    "# Boxing the coordinates with +- 0.0025 which translates to around 200m around the original point\n",
    "stopping_locations = stopping_locations \\\n",
    "                        .withColumn(\"top_box\", round(col(\"Latitude\") + 0.0025, 3)) \\\n",
    "                        .withColumn(\"bottom_box\", round(col(\"Latitude\") - 0.0025, 3)) \\\n",
    "                        .withColumn(\"left_box\", round(col(\"Longitude\") + 0.0025, 3)) \\\n",
    "                        .withColumn(\"right_box\", round(col(\"Longitude\") - 0.0025, 3))\n",
    "\n",
    "# The most popular stopping locations here are those locations with the most visits by distinct vehicles\n",
    "stopping_locations \\\n",
    "    .groupBy([\"top_box\", \"bottom_box\", \"left_box\", \"right_box\"]) \\\n",
    "    .agg(countDistinct(\"VehId\").alias(\"num_unique_vehicles\"), count(\"VehId\").alias(\"num_stops\")) \\\n",
    "    .sort(col(\"num_unique_vehicles\").desc()) \\\n",
    "    .show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that the most popular stopping location has had 121 trips start or end in it, with 44 distinct vehicles. Looking at the map this location seems to be around Concordia University Ann Arbor\n",
    "\n",
    "## 3- What is the most frequent trip?\n",
    "\n",
    "Here we want to see what is the pair of two stopping locations that make up a trip that has been made the most times by drivers. Again, it is also interesting to look beyond the number of trips and see how many distinct drivers made this trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------------+-------------+----------------+---------+\n",
      "|Latitude|Longitude|End_latitude|End_longitude|num_unique_trips|num_trips|\n",
      "+--------+---------+------------+-------------+----------------+---------+\n",
      "|  42.309|  -83.677|      42.303|      -83.704|               5|        5|\n",
      "+--------+---------+------------+-------------+----------------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rename lat and long column of end_locations and join the two dataframes on DayNum and VehId\n",
    "# Also round coordinates to 3 decimal places\n",
    "# Droping the average and median speed from end_locations since start_locations already has that same info\n",
    "trips_df = start_locations \\\n",
    "    .join(\n",
    "        end_locations \\\n",
    "            .drop(\"Average_Speed\", \"Median_Speed\")\\\n",
    "            .withColumnRenamed(\"Latitude\", \"End_latitude\") \\\n",
    "            .withColumnRenamed(\"Longitude\", \"End_longitude\"),\n",
    "        [\"DayNum\", \"VehId\"]\n",
    "    ) \\\n",
    "    .withColumn(\"Latitude\", round(col(\"Latitude\"), 3)) \\\n",
    "    .withColumn(\"Longitude\", round(col(\"Longitude\"), 3)) \\\n",
    "    .withColumn(\"End_latitude\", round(col(\"End_latitude\"), 3)) \\\n",
    "    .withColumn(\"End_longitude\", round(col(\"End_longitude\"), 3))\n",
    "\n",
    "# Get the trip with the largest value of trips by distinct vehicles\n",
    "trips_df \\\n",
    "    .groupBy([\"Latitude\", \"Longitude\", \"End_latitude\", \"End_longitude\"]) \\\n",
    "    .agg(countDistinct(\"VehId\").alias(\"num_unique_trips\"), count(\"VehId\").alias(\"num_trips\")) \\\n",
    "    .orderBy([\"num_trips\", \"num_unique_trips\"], ascending=False) \\\n",
    "    .show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most frequent trip has been made 5 times by 5 different vehicles.\n",
    "\n",
    "Looking at this trip in a map we can see this trip begins in a comercial area and ends in the east campus of the University of Michigan. The trips starts near a starbucks and a McDonald's so I'm guessing these are 5 different people who all went out to lunch and a coffee before going to college :)\n",
    "\n",
    "## 4- What are the trips with the highest and lowest average speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+---------+------------------+------------+------------+-------------+\n",
      "|  DayNum|VehId|Latitude|Longitude|     Average_speed|Median_Speed|End_latitude|End_longitude|\n",
      "+--------+-----+--------+---------+------------------+------------+------------+-------------+\n",
      "|12.91785|  285|  42.274|  -83.675|2.6194029850746268|         0.0|      42.274|      -83.674|\n",
      "|8.384305|  557|  42.288|  -83.747|104.56752873563218|       117.0|      42.239|      -83.738|\n",
      "+--------+-----+--------+---------+------------------+------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_query = trips_df \\\n",
    "    .select(min(\"Average_Speed\"), max(\"Average_Speed\"), min(\"Median_Speed\"), max(\"Median_Speed\")) \\\n",
    "    .collect()[0]\n",
    "\n",
    "min_avg_speed, max_avg_speed = result_query[\"min(Average_Speed)\"], result_query[\"max(Average_Speed)\"]\n",
    "min_median_speed, max_median_speed = result_query[\"min(Median_Speed)\"], result_query[\"max(Median_Speed)\"]\n",
    "\n",
    "trips_df \\\n",
    "    .where((trips_df[\"Average_Speed\"] == min_avg_speed) | (trips_df[\"Average_Speed\"] == max_avg_speed)) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the the lowest average speed in a trip was around 2 km/h and the highest average speed in a trip was around 104 km/h. However in cases such as speed it might prove more informative to use the median instead of the average since the average can be heavily influence by outliers (such as stopping, or speeding in a highway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+--------+---------+------------------+------------+------------+-------------+\n",
      "|   DayNum|VehId|Latitude|Longitude|     Average_speed|Median_Speed|End_latitude|End_longitude|\n",
      "+---------+-----+--------+---------+------------------+------------+------------+-------------+\n",
      "|7.7071733|  269|  42.257|  -83.696|18.852601156069365|         0.0|      42.231|       -83.68|\n",
      "|1.4773134|  189|  42.269|  -83.747|5.8647373387857815|         0.0|      42.269|      -83.747|\n",
      "|4.3980327|  163|  42.245|  -83.703|13.918650793650794|         0.0|      42.246|      -83.681|\n",
      "|11.116269|  195|  42.289|  -83.747| 8.808783165599268|         0.0|      42.291|       -83.74|\n",
      "|3.7202237|  163|  42.245|   -83.68| 9.384969325153374|         0.0|      42.253|      -83.676|\n",
      "|10.532848|  189|  42.269|  -83.747| 5.963488843813387|         0.0|      42.272|      -83.745|\n",
      "| 4.937109|  547|  42.245|  -83.694| 17.31063829787234|         0.0|      42.246|      -83.681|\n",
      "| 12.91785|  285|  42.274|  -83.675|2.6194029850746268|         0.0|      42.274|      -83.674|\n",
      "|6.0241513|  208|  42.256|   -83.69|10.045698924731182|         0.0|      42.246|      -83.681|\n",
      "| 8.384305|  557|  42.288|  -83.747|104.56752873563218|       117.0|      42.239|      -83.738|\n",
      "|13.925435|  179|  42.245|    -83.7|3.6666666666666665|         0.0|      42.245|      -83.701|\n",
      "+---------+-----+--------+---------+------------------+------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_df \\\n",
    "    .where((trips_df[\"Median_Speed\"] == min_median_speed) | (trips_df[\"Median_Speed\"] == max_median_speed)) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the results for the median speed don't differ that much from the average speed. Actually both the maximum and the minimum median speed coincide with the results for the average. This might be because a portion of the start and end of the trip is supressed and so they rarely start at 0, diminishing the outliers that might influence the average.\n",
    "\n",
    "However we also get some additional information. Looking at, for example, the first row (with `VehId == 269`) we see that the average speed is 18.9 but the median is 0. These are cases of trips were the driver was stopped (`speed==0`) for the majority of the trip and was only moving for a small part of the trip. This could lead us to investigate these cases further to search for a specific pattern\n",
    "\n",
    "## 5- Discussing the anonymization process\n",
    "\n",
    "Reading section _III. De-Identification_ of the paper, some points can be brought of:\n",
    "\n",
    "- Due to the fogging mechanism, short trips might either be completely fogged or don't have any useful information. In this cases it might be better to filter out short trips.\n",
    "\n",
    "- Due to the fencing mechanism trips some stopping points outside the city that may be useful to know are also supressed, discarding this information. In the authors defence, their work is more pointed to the study of fuel and energy consumption than rather the study of trips\n",
    "\n",
    "- Common stopping points in the middle of the trip are not removed. Both start and end locations are supressed from the trips, but stopping locations in the middle of the trip are not. Say for example the user always goes by the same drive-thru restaurant in the middle of the trip, this might lead to possibly identifying the user\n",
    "\n",
    "- Drivers that always take the same routes might also not be completly anonymized. Granted that the start and end locantions are supressed, but if the driver always performs the same trajectory, than this can lead to possible identification of the driver. This may be addressed by removing common locations where a driver frequently stops in his trip, although  it impacts the quality of the data\n",
    "\n",
    "- Furthermore, it may also be possible to get a representation of the driver, either by the route, the average speed, car-consumption information, etc.\n",
    "\n",
    "- Considering the last two points with eletric or hybrid vehicles may narrow down the search of a drivers identity due to the rarity of these types of vehicles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
