{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tb.lx Data Science Challenge - Part II\n",
    "----\n",
    "----\n",
    "## Introduction\n",
    "\n",
    "Dear applicant,\n",
    "\n",
    "Congratulations on passing the first screening! We’re excited to get to know you better and get a better feeling of your competences. In this round, we will test you on your problem-solving skills and data science experience by giving you a case to solve.\n",
    "\n",
    "After handing us over your solution, we will review it and let you know our feedback. In the case you have passed, you will be called to an on-site interview. During the interview, you’ll get the opportunity to explain your solution and the steps that you took to get there. We've prepared this notebook for you, to help you walk us through your ideas and decisions.\n",
    "\n",
    "If you're not able to fully solve the case, please elaborate as precisely as you can:\n",
    "\n",
    "- Which next steps you'd be taking;\n",
    "- Which problems you'd be foreseeing there and how you'd solve those.\n",
    "\n",
    "In case you have any questions, feel free to contact ana.cunha@daimler.com or sara.gorjao@daimler.com for any more info. \n",
    "\n",
    "Best of luck!\n",
    "\n",
    "## Context:\n",
    "\n",
    "Predictive Maintenance is one of the hottest topics in the heavy-industry field. The ability to detect failures before they happen is of utmost importance, as it enables the full utilization of materials saving in unnecessary early replacements, and enables optimizations in maintenance planning reducing the downtime.\n",
    "\n",
    "\n",
    "## Data:\n",
    "\n",
    "One of the challenges in the auto-tech industry is to detect failures before they happen. For this, we included a dataset including:\n",
    "* `telemetry.csv`: Consists of a dataset with sensor values along time\n",
    "* `faults.csv`: Consists of a dataset with faults for each machine along time.\n",
    "* `errors.csv`: Consists of a dataset with errors for each machine along time.\n",
    "* `machines.csv`: Consists of a dataset with features for each machine. \n",
    "\n",
    "\n",
    "## Task:\n",
    "\n",
    "In the second part of the challenge, we would like to know that a failure is going to happen before it actually happens. The decision of the prediction horizon is totally up to you, **but the goal is to predict failures before they happen**.\n",
    "\n",
    "\n",
    "## Questions:\n",
    "\n",
    "Follows a set of theoretical questions:\n",
    "\n",
    "1. How can you create a machine learning model that leverages all the data that we provided whilst adapting to the specificities of each turbine (e.g., operating in different weather conditions)?\n",
    "2. Modeling the normal behaviour of such machines can prove itself to be a good feature. After training a model that captures the normal turbine dynamics, we need to decide when the displayed behaviour may be considered an anomaly or not. How can one design a framework that creates alerts for abnormality without overloading the end-user with too many false positives?\n",
    "3. How would you measure aleatoric uncertainty of the predictions of your model?\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "- Solution implemented in Python3.6+;\n",
    "- Provide requirements.txt to test the solution in the same environment;\n",
    "- Write well structured, documented, maintainable code;\n",
    "- Write sanity checks to test the different steps of the pipeline;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isto aqui vai ser muito como as coisas que ja tenho visto de TTF. Load datasets ver o RUL ver quantos time-steps faltam\n",
    "# até o RUL e por ai fora\n",
    "#https://www.kaggle.com/nafisur/predictive-maintenance-using-lstm-on-sensor-data\n",
    "#https://www.kaggle.com/billstuart/predictive-maintenance-ml-iiot\n",
    "#https://www.kaggle.com/hanwsf8/lstm-lgb-catb-for-predictive-maintenance-upper\n",
    "#https://www.kaggle.com/juhumbertaf/tutorial\n",
    "#https://iopscience.iop.org/article/10.1088/1742-6596/1037/6/062003/pdf\n",
    "#https://www.kaggle.com/c/equipfails/overview\n",
    "#https://www.kaggle.com/uciml/aps-failure-at-scania-trucks-data-set\n",
    "#https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/predictive-maintenance-playbook#data-science-for-predictive-maintenance\n",
    "#https://github.com/Azure-Samples/MachineLearningSamples-DeepLearningforPredictiveMaintenance\n",
    "#https://gallery.azure.ai/Notebook/Predictive-Maintenance-Implementation-Guide-R-Notebook-2\n",
    "#https://gallery.azure.ai/Collection/Predictive-Maintenance-Template-3\n",
    "\n",
    "# Para a primeira pergunta: Dizer algo como garantir que o modelo não esta a fazer overfitting de maneira a conseguir\n",
    "# adaptar-se a novas turbinas (também posso dizer \"garantir que os dados são representativos do que queremos\")\n",
    "\n",
    "# Para a segunda pergunta: Fazer one class classification\n",
    "\n",
    "# Para a terceira pergunta: algo como bayesian estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Loading the datasets\n",
    "telemetry = pd.read_csv(\"../data/sensor/telemetry.csv\", index_col=0)\n",
    "failures = pd.read_csv(\"../data/sensor/failures.csv\")\n",
    "errors = pd.read_csv(\"../data/sensor/errors.csv\")\n",
    "machines = pd.read_csv(\"../data/sensor/machines.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting datetime strings to datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry[\"datetime\"] = pd.to_datetime(telemetry[\"datetime\"])\n",
    "failures[\"datetime\"] = pd.to_datetime(failures[\"datetime\"])\n",
    "errors[\"datetime\"] = pd.to_datetime(errors[\"datetime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining the additional information\n",
    "\n",
    "Since we have other relevant information scattered on different dataframes, it is useful to  join these dataframes into one containing all the needed information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>volt</th>\n",
       "      <th>rotate</th>\n",
       "      <th>pressure</th>\n",
       "      <th>vibration</th>\n",
       "      <th>failures</th>\n",
       "      <th>errorID</th>\n",
       "      <th>model</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>176.217853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.077935</td>\n",
       "      <td>45.087686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 07:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>162.879223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.460525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 08:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527.349825</td>\n",
       "      <td>75.237905</td>\n",
       "      <td>34.178847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>162.462833</td>\n",
       "      <td>346.149335</td>\n",
       "      <td>109.248561</td>\n",
       "      <td>41.122144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01 10:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>157.610021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.886648</td>\n",
       "      <td>25.990511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  machineID        volt      rotate    pressure  \\\n",
       "0 2015-01-01 06:00:00          1  176.217853         NaN  113.077935   \n",
       "1 2015-01-01 07:00:00          1  162.879223         NaN   95.460525   \n",
       "2 2015-01-01 08:00:00          1         NaN  527.349825   75.237905   \n",
       "3 2015-01-01 09:00:00          1  162.462833  346.149335  109.248561   \n",
       "4 2015-01-01 10:00:00          1  157.610021         NaN  111.886648   \n",
       "\n",
       "   vibration  failures    errorID   model  age  \n",
       "0  45.087686       0.0  no_errors  model3   18  \n",
       "1        NaN       0.0  no_errors  model3   18  \n",
       "2  34.178847       0.0  no_errors  model3   18  \n",
       "3  41.122144       0.0  no_errors  model3   18  \n",
       "4  25.990511       0.0  no_errors  model3   18  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining the newly added failures column to the telemetry dataframe\n",
    "failures[\"failures\"] = 1\n",
    "telemetry = telemetry.merge(failures, on=[\"machineID\", \"datetime\"], how=\"left\")\n",
    "telemetry[\"failures\"].fillna(0, inplace=True)\n",
    "\n",
    "# Joining the errors columns to the telemetry dataframe\n",
    "telemetry = telemetry.merge(errors, on=[\"machineID\", \"datetime\"], how=\"left\")\n",
    "telemetry[\"errorID\"].fillna(\"no_errors\", inplace=True)\n",
    "\n",
    "# Joining the static machine information to the telemetry dataframe\n",
    "telemetry = telemetry.merge(machines, on=\"machineID\", how=\"left\")\n",
    "telemetry.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a complete dataset with time-series data and static data to use. We can see there are some missing values present in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime          0\n",
       "machineID         0\n",
       "volt         139548\n",
       "rotate       139597\n",
       "pressure     139461\n",
       "vibration    139558\n",
       "failures          0\n",
       "errorID           0\n",
       "model             0\n",
       "age               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telemetry.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing data\n",
    "\n",
    "Nearly 16% of the `volt`, `rotate`, `pressure` and `vibration` columns are missing which is a good portion of the data. Given the size of the missing data it discards the possibility of simply dropping rows with missing values in them, as that would have too much of an impact in the quality of our data.\n",
    "\n",
    "What we can do instead is to impute the missing values with a value that makes sense. This value can be the mean, mode, median, etc. of these columns. However different machines might have different mean/median/mdode values for these columns so it is imporant to impute these values with consideration about which machine is being imputed.\n",
    "\n",
    "Since the missing values are in the dynamic data columns, we can go one step further than imputting with just the mean for example. Since these values change over time we can impute the missing values with a linea interpolation of the previous points in order to minimize the disruption in the data, giving us the best possible value for our missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df, group_column, column_name, interpolate=True):\n",
    "    \"\"\"\n",
    "        Fills the missing values in column_name by either the interpolated value (if interpolate is True)\n",
    "        or the mean of the taken from from each group in group_column\n",
    "        \n",
    "        Arguments:\n",
    "            df: The dataframe to update\n",
    "            group_column: The name of the column by which to group the data\n",
    "            column_name: The name of the column in which to replace the missing values\n",
    "            interpolate: Boolean flag indicating if the missing values should be imputed with the interpolated\n",
    "                value or by the mean\n",
    "                \n",
    "        Returns:\n",
    "            A pd.Series object with missing value replaced by a meaningful value, to replace the original column\n",
    "            in the dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    if interpolate:\n",
    "        return df.groupby(group_column)[column_name].apply(lambda x: x.fillna(x.interpolate(method='linear')))\n",
    "    else:\n",
    "        return df.groupby(group_column)[column_name].apply(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "\n",
    "for column in [\"volt\", \"rotate\", \"pressure\", \"vibration\"]:\n",
    "    \n",
    "    # Impute missing values with the interpolated values\n",
    "    telemetry[column] = fill_missing_values(telemetry, \"machineID\", column)\n",
    "    \n",
    "    # Some missing values may still persists (in cases where interpolation is not possible) for those \n",
    "    # we'll impute with the mean\n",
    "    telemetry[column] = fill_missing_values(telemetry, \"machineID\", column, interpolate=False)\n",
    "    \n",
    "# Checking the missing values\n",
    "telemetry.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, no more missing values in our data\n",
    "\n",
    "## Adding cycle and time to next failure information\n",
    "\n",
    "Since we are trying to predict when a machine will fail it is also usefull to know for every observation how many cycles are left until it fails. For that we need the information about the cycle of an observation (a cumulative count for a specific machine)\n",
    "\n",
    "Having both these additional columns allows us to create a binary label for our data (e.g. \"this machine fails in X number of cycles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding information about the cycle of each machine\n",
    "telemetry[\"cycle\"] = telemetry.groupby(\"machineID\").cumcount()\n",
    "\n",
    "def get_failure_cycles():\n",
    "    \"\"\"\n",
    "        Gets a hash-map (a python dictionary) of all the cycles where a fail occured for each machine, for faster lookup times\n",
    "        Hash-Map format {machineID: <List of cycles where fail occured>}\n",
    "        \n",
    "        Returns:\n",
    "            A hash-map containing a list of cycles where each machine failed\n",
    "    \"\"\"\n",
    "    \n",
    "    hash_map = {}\n",
    "    \n",
    "    # Iterate over every machineID\n",
    "    for machine_id in telemetry[\"machineID\"].unique():\n",
    "        \n",
    "        # Get the list of cycles where a failure occured for this machine\n",
    "        failure_cycles = telemetry.loc[(telemetry[\"machineID\"] == machine_id) & (telemetry[\"failures\"] == 1), \"cycle\"].to_numpy()\n",
    "        \n",
    "        # Insert new key and new value to hash-map\n",
    "        hash_map[machine_id] = np.unique(failure_cycles)\n",
    "        \n",
    "    return hash_map\n",
    "\n",
    "# hash-map containing every failure cycles for all machines\n",
    "failure_cycles = get_failure_cycles()\n",
    "\n",
    "def add_time_to_failure(row, failure_cycles):\n",
    "    \"\"\"\n",
    "        Calculates the number of cycles left until a failure is observed, \n",
    "        based on the currect cycle of the current machine.\n",
    "        \n",
    "        The observations between the last known failure and the end of the analysis have a common time-to-failure\n",
    "        of 9999 since these observations are censored and a failure is not garanteed.\n",
    "        \n",
    "        Arguments:\n",
    "            row: The current row of the telemetry dataframe being iterated\n",
    "            failure_cycles: The dictonary containing the failures cycles for each machine\n",
    "        \n",
    "        Returns:\n",
    "            The number of cycles left until a machine experiences a failure\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the list of failure cycles for this machine\n",
    "    machine_failure_cycles = failure_cycles[row[\"machineID\"]]\n",
    "    \n",
    "    # If the current cycle is a failure cycle, then return 0 (there are 0 cycles until a failure is observed)\n",
    "    if row[\"cycle\"] in machine_failure_cycles:\n",
    "        return 0\n",
    "    \n",
    "    # Get the index in which the current cycle of this machine would be added\n",
    "    # in the list of failures for this machine. This index holds the value of of the next failure cycle\n",
    "    #\n",
    "    # Example: \n",
    "    #\n",
    "    #    arr = [96, 150, 300]\n",
    "    #    current_cycle = 50\n",
    "    #\n",
    "    #    idx_of_next_failure = bisect.bisect(arr, current_cycle)\n",
    "    #    idx_of_next_failure\n",
    "    #    >> 0\n",
    "    #    arr[idx_of_next_failure]\n",
    "    #    >> 96\n",
    "    #\n",
    "    #    current_cycle = 200\n",
    "    #    idx_of_next_failure = bisect.bisect(arr, current_cycle)\n",
    "    #    idx_of_next_failure\n",
    "    #    >> 2\n",
    "    #    arr[idx_of_next_failure]\n",
    "    #    >> 300\n",
    "    next_failure_index = bisect.bisect(machine_failure_cycles, row[\"cycle\"])\n",
    "\n",
    "\n",
    "    if next_failure_index < len(machine_failure_cycles):\n",
    "        \n",
    "        # Calculates the number of cycles left until a failure cycle\n",
    "        return machine_failure_cycles[next_failure_index] - row[\"cycle\"]\n",
    "    else:\n",
    "        \n",
    "        # Between the last known failure of a machine and the end of the analysis\n",
    "        # the time to failure doesn't matter much, so we'll fill it with a mask value of 9999\n",
    "        return 9999\n",
    "    \n",
    "    \n",
    "telemetry[\"ttf\"] = telemetry.apply(lambda row: add_time_to_failure(row, failure_cycles), axis=1)\n",
    "telemetry.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the labels\n",
    "\n",
    "In order to predict a failure before it happens we need to lag the information about the failure back a few cycles so our model can learn a failure pattern before it happens.\n",
    "\n",
    "Looking at the data we see that each cycle (an observation of each machine) represents one hour. Given this we might lag our failure column 15 cycles back in order to predict failures from at most 15 hours in advance. (__SECALHAR AQUI DEVO RETIRAR TAMBÉM A OBSERVAÇÃO NO MOMENTO DA FALHA PORQUE NÃO ME INTERESSE PREVER QUANDO FALHOU__) __quando separar para train test se calhar tambem tenho que tirar algumas observacoes perto do corte para garantir que nao ha leakage__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>volt</th>\n",
       "      <th>rotate</th>\n",
       "      <th>pressure</th>\n",
       "      <th>vibration</th>\n",
       "      <th>failures</th>\n",
       "      <th>errorID</th>\n",
       "      <th>model</th>\n",
       "      <th>age</th>\n",
       "      <th>cycle</th>\n",
       "      <th>ttf</th>\n",
       "      <th>fails_in_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2015-01-04 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>129.016707</td>\n",
       "      <td>479.457721</td>\n",
       "      <td>111.575038</td>\n",
       "      <td>46.098007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2015-01-04 15:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>168.503141</td>\n",
       "      <td>455.536868</td>\n",
       "      <td>83.689837</td>\n",
       "      <td>43.917862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>81</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2015-01-04 16:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>184.640476</td>\n",
       "      <td>365.213804</td>\n",
       "      <td>87.474009</td>\n",
       "      <td>45.434177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2015-01-04 17:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>176.208034</td>\n",
       "      <td>517.348533</td>\n",
       "      <td>82.400818</td>\n",
       "      <td>46.950492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>83</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2015-01-04 18:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>187.982008</td>\n",
       "      <td>487.487012</td>\n",
       "      <td>111.684659</td>\n",
       "      <td>56.837165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2015-01-04 19:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>199.755983</td>\n",
       "      <td>457.625491</td>\n",
       "      <td>107.335080</td>\n",
       "      <td>41.674887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>85</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2015-01-04 20:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>181.062464</td>\n",
       "      <td>427.763970</td>\n",
       "      <td>103.159963</td>\n",
       "      <td>50.146515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>86</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2015-01-04 21:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>162.368945</td>\n",
       "      <td>458.491868</td>\n",
       "      <td>96.210047</td>\n",
       "      <td>50.240045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>87</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2015-01-04 22:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>180.562703</td>\n",
       "      <td>447.101400</td>\n",
       "      <td>89.260131</td>\n",
       "      <td>56.352074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2015-01-04 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>171.245820</td>\n",
       "      <td>471.194987</td>\n",
       "      <td>89.474271</td>\n",
       "      <td>62.464103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>89</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2015-01-05 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>161.928938</td>\n",
       "      <td>376.719605</td>\n",
       "      <td>89.969588</td>\n",
       "      <td>58.087488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2015-01-05 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>127.163620</td>\n",
       "      <td>430.475185</td>\n",
       "      <td>95.667178</td>\n",
       "      <td>46.845600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2015-01-05 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>158.155297</td>\n",
       "      <td>429.346217</td>\n",
       "      <td>94.892589</td>\n",
       "      <td>58.225151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>92</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2015-01-05 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>177.317220</td>\n",
       "      <td>461.801246</td>\n",
       "      <td>103.056344</td>\n",
       "      <td>49.894647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2015-01-05 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>202.520488</td>\n",
       "      <td>387.005318</td>\n",
       "      <td>105.981906</td>\n",
       "      <td>45.202347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2015-01-05 05:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>177.510419</td>\n",
       "      <td>469.787301</td>\n",
       "      <td>108.907467</td>\n",
       "      <td>59.577251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2015-01-05 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>166.510936</td>\n",
       "      <td>484.092868</td>\n",
       "      <td>111.833028</td>\n",
       "      <td>52.383097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2015-01-05 07:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>155.511452</td>\n",
       "      <td>498.398435</td>\n",
       "      <td>103.068134</td>\n",
       "      <td>33.270415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>97</td>\n",
       "      <td>1439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2015-01-05 08:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>172.439821</td>\n",
       "      <td>392.124959</td>\n",
       "      <td>108.135159</td>\n",
       "      <td>39.477497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>98</td>\n",
       "      <td>1438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2015-01-05 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>138.826437</td>\n",
       "      <td>451.348967</td>\n",
       "      <td>126.464580</td>\n",
       "      <td>38.257462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_errors</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "      <td>99</td>\n",
       "      <td>1437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  machineID        volt      rotate    pressure  \\\n",
       "80 2015-01-04 14:00:00          1  129.016707  479.457721  111.575038   \n",
       "81 2015-01-04 15:00:00          1  168.503141  455.536868   83.689837   \n",
       "82 2015-01-04 16:00:00          1  184.640476  365.213804   87.474009   \n",
       "83 2015-01-04 17:00:00          1  176.208034  517.348533   82.400818   \n",
       "84 2015-01-04 18:00:00          1  187.982008  487.487012  111.684659   \n",
       "85 2015-01-04 19:00:00          1  199.755983  457.625491  107.335080   \n",
       "86 2015-01-04 20:00:00          1  181.062464  427.763970  103.159963   \n",
       "87 2015-01-04 21:00:00          1  162.368945  458.491868   96.210047   \n",
       "88 2015-01-04 22:00:00          1  180.562703  447.101400   89.260131   \n",
       "89 2015-01-04 23:00:00          1  171.245820  471.194987   89.474271   \n",
       "90 2015-01-05 00:00:00          1  161.928938  376.719605   89.969588   \n",
       "91 2015-01-05 01:00:00          1  127.163620  430.475185   95.667178   \n",
       "92 2015-01-05 02:00:00          1  158.155297  429.346217   94.892589   \n",
       "93 2015-01-05 03:00:00          1  177.317220  461.801246  103.056344   \n",
       "94 2015-01-05 04:00:00          1  202.520488  387.005318  105.981906   \n",
       "95 2015-01-05 05:00:00          1  177.510419  469.787301  108.907467   \n",
       "96 2015-01-05 06:00:00          1  166.510936  484.092868  111.833028   \n",
       "97 2015-01-05 07:00:00          1  155.511452  498.398435  103.068134   \n",
       "98 2015-01-05 08:00:00          1  172.439821  392.124959  108.135159   \n",
       "99 2015-01-05 09:00:00          1  138.826437  451.348967  126.464580   \n",
       "\n",
       "    vibration  failures    errorID   model  age  cycle   ttf  fails_in_15  \n",
       "80  46.098007       0.0  no_errors  model3   18     80    16            0  \n",
       "81  43.917862       0.0  no_errors  model3   18     81    15            1  \n",
       "82  45.434177       0.0  no_errors  model3   18     82    14            1  \n",
       "83  46.950492       0.0  no_errors  model3   18     83    13            1  \n",
       "84  56.837165       0.0  no_errors  model3   18     84    12            1  \n",
       "85  41.674887       0.0  no_errors  model3   18     85    11            1  \n",
       "86  50.146515       0.0  no_errors  model3   18     86    10            1  \n",
       "87  50.240045       0.0  no_errors  model3   18     87     9            1  \n",
       "88  56.352074       0.0  no_errors  model3   18     88     8            1  \n",
       "89  62.464103       0.0  no_errors  model3   18     89     7            1  \n",
       "90  58.087488       0.0  no_errors  model3   18     90     6            1  \n",
       "91  46.845600       0.0  no_errors  model3   18     91     5            1  \n",
       "92  58.225151       0.0  no_errors  model3   18     92     4            1  \n",
       "93  49.894647       0.0  no_errors  model3   18     93     3            1  \n",
       "94  45.202347       0.0  no_errors  model3   18     94     2            1  \n",
       "95  59.577251       0.0  no_errors  model3   18     95     1            1  \n",
       "96  52.383097       1.0  no_errors  model3   18     96     0            1  \n",
       "97  33.270415       0.0  no_errors  model3   18     97  1439            0  \n",
       "98  39.477497       0.0  no_errors  model3   18     98  1438            0  \n",
       "99  38.257462       0.0  no_errors  model3   18     99  1437            0  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fail_window = 15\n",
    "telemetry['fails_in_15'] = np.where(telemetry['ttf'] <= fail_window, 1, 0)\n",
    "\n",
    "# Viewing that our `fails_in_15` column is correct\n",
    "telemetry.iloc[80:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that at cycle 81 (15 cycles before machine 1 witnesses a failure) we start labeling observations as \"will fail within a window of 15 cycles\". This gives us 15 cycles (which translates to 15 hours) to predict this failure. \n",
    "\n",
    "With more domain knowledge about the concrete situation a better number of cycles to predict could be thought of, although for this exercise this may suffice.\n",
    "\n",
    "We now have a binary label that we can use for a classifier. We could also create different labels (e.g. \"fails in 30 cycles\", \"fails in 40 cycles\") where we could perform multiclass-classification. We could also use this as a regression problem and try to predict the time to failure, although this could be harder for the machine learning model to predict, and we would have to possibily discard the observations between the last known failure and the end of the analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
